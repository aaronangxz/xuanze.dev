"use strict";(self.webpackChunkleetcode_notes=self.webpackChunkleetcode_notes||[]).push([[7324],{3905:(e,t,r)=>{r.d(t,{Zo:()=>c,kt:()=>m});var i=r(7294);function n(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function a(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,i)}return r}function o(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?a(Object(r),!0).forEach((function(t){n(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function s(e,t){if(null==e)return{};var r,i,n=function(e,t){if(null==e)return{};var r,i,n={},a=Object.keys(e);for(i=0;i<a.length;i++)r=a[i],t.indexOf(r)>=0||(n[r]=e[r]);return n}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(i=0;i<a.length;i++)r=a[i],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(n[r]=e[r])}return n}var l=i.createContext({}),u=function(e){var t=i.useContext(l),r=t;return e&&(r="function"==typeof e?e(t):o(o({},t),e)),r},c=function(e){var t=u(e.components);return i.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},h=i.forwardRef((function(e,t){var r=e.components,n=e.mdxType,a=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),h=u(r),m=n,p=h["".concat(l,".").concat(m)]||h[m]||d[m]||a;return r?i.createElement(p,o(o({ref:t},c),{},{components:r})):i.createElement(p,o({ref:t},c))}));function m(e,t){var r=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var a=r.length,o=new Array(a);o[0]=h;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:n,o[1]=s;for(var u=2;u<a;u++)o[u]=r[u];return i.createElement.apply(null,o)}return i.createElement.apply(null,r)}h.displayName="MDXCreateElement"},3489:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>a,metadata:()=>s,toc:()=>u});var i=r(7462),n=(r(7294),r(3905));const a={displayed_sidebar:"notesSideBar"},o="Rate Limiter",s={unversionedId:"notes/System Design/RateLimiter",id:"notes/System Design/RateLimiter",title:"Rate Limiter",description:"Algorithms",source:"@site/docs/notes/System Design/RateLimiter.md",sourceDirName:"notes/System Design",slug:"/notes/System Design/RateLimiter",permalink:"/XZ-LeetCode-Journal/docs/notes/System Design/RateLimiter",draft:!1,tags:[],version:"current",frontMatter:{displayed_sidebar:"notesSideBar"},sidebar:"notesSideBar",previous:{title:"Random ID Generator",permalink:"/XZ-LeetCode-Journal/docs/notes/System Design/RandomIdGenerator"},next:{title:"Terms",permalink:"/XZ-LeetCode-Journal/docs/notes/System Design/Terms"}},l={},u=[{value:"Algorithms",id:"algorithms",level:2},{value:"Fixed window algorithm",id:"fixed-window-algorithm",level:3},{value:"Sliding window algorithm",id:"sliding-window-algorithm",level:3},{value:"Token bucket algorithm",id:"token-bucket-algorithm",level:3},{value:"Leaky-bucket algorithm",id:"leaky-bucket-algorithm",level:3},{value:"Other Ways",id:"other-ways",level:2}],c={toc:u};function d(e){let{components:t,...r}=e;return(0,n.kt)("wrapper",(0,i.Z)({},c,r,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"rate-limiter"},"Rate Limiter"),(0,n.kt)("h2",{id:"algorithms"},"Algorithms"),(0,n.kt)("h3",{id:"fixed-window-algorithm"},"Fixed window algorithm"),(0,n.kt)("p",null,"The system uses a window size of n seconds (typically using human-friendly values, such as 60 or 3600 seconds) to track the fixed window algorithm rate. Each incoming request increments the counter for the window. It discards the request if the counter exceeds a threshold. The current timestamp floor typically defines the windows, so 12:00:03, with a 60-second window length, would be in the 12:00:00 window."),(0,n.kt)("p",null,"Pros: ensures more recent requests get processed without being starved by old requests"),(0,n.kt)("p",null,"Cons: a single burst of traffic that occurs near the boundary of a window can result in the processing of twice the rate of requests because it will allow requests for both the current and next windows within a short time. If many consumers wait for a reset window, they may stampede your API at the same time at the top of the hour. "),(0,n.kt)("h3",{id:"sliding-window-algorithm"},"Sliding window algorithm"),(0,n.kt)("p",null,"Sliding Window is a hybrid approach that combines the fixed window algorithm\u2019s low processing cost and the sliding log\u2019s improved boundary conditions. Like the fixed window algorithm, we track a counter for each fixed window. Next, we account for a weighted value of the previous window\u2019s request rate based on the current timestamp to smooth out bursts of traffic. For example, if the current window is 25% through, we weigh the previous window\u2019s count by 75%. The relatively small number of data points needed to track per key allows us to scale and distribute across large clusters."),(0,n.kt)("p",null,"Pros: flexibility to scale rate limiting with good performance."),(0,n.kt)("h3",{id:"token-bucket-algorithm"},"Token bucket algorithm"),(0,n.kt)("p",null,"The token bucket algorithm maintains a fixed capacity bucket where a tokens are added at a fixed rate. The tokens in most cases is a single request or in some cases, it can be network packets. When the bucket is full, the service is considered to have reached its limit and responds with backpressure. This algorithm is used when there is a case where not all inputs correspond to 1:1 with requests. For instance, a request to a service can make multiple database calls and then return a result. Each database call may take one token."),(0,n.kt)("h3",{id:"leaky-bucket-algorithm"},"Leaky-bucket algorithm"),(0,n.kt)("p",null,"Leaky bucket (closely related to token bucket) is an algorithm that provides a simple, intuitive approach to rate limiting via a queue, which you can think of as a bucket holding the requests. When registering a request, the system appends it to the end of the queue. Processing for the first item on the queue occurs at a regular interval or first in, first out (FIFO). If the queue is full, then additional requests are discarded (or leaked)."),(0,n.kt)("p",null,"Pros: smooths out bursts of requests and processes them at an approximately average rate"),(0,n.kt)("p",null,"Cons: a burst of traffic can fill up the queue with old requests and starve more recent requests from being processed. No guarantee that requests get processed in a fixed amount of time"),(0,n.kt)("h2",{id:"other-ways"},"Other Ways"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Channels"),(0,n.kt)("li",{parentName:"ul"},"Ticker"),(0,n.kt)("li",{parentName:"ul"},"Cache ")),(0,n.kt)("p",null,"References"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://ayada.dev/posts/ways-to-rate-limit-requests-in-go/"},"https://ayada.dev/posts/ways-to-rate-limit-requests-in-go/")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://konghq.com/blog/how-to-design-a-scalable-rate-limiting-algorithm"},"https://konghq.com/blog/how-to-design-a-scalable-rate-limiting-algorithm"))))}d.isMDXComponent=!0}}]);